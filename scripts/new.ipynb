{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2b7b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d512b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uname_result(system='Linux', node='scc-x05', release='4.18.0-553.54.1.el8_10.x86_64', version='#1 SMP Tue May 27 22:49:52 EDT 2025', machine='x86_64')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "platform.uname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c80117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_email(text: str) -> str:\n",
    "    text = re.sub(r'<[^>]+>', '', text) # remove HTML tags\n",
    "    text = re.sub(r'http\\S+', '', text) # remove URLs\n",
    "    # TODO: add a count of URLs to email data\n",
    "    text = re.sub(r'\\d+', '', text) # remove numerical text\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove punctuation\n",
    "    text = text.lower().strip() # lowercase\n",
    "    return text\n",
    "\n",
    "def preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    df['clean_email'] = df['body'].astype(str).apply(clean_email)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d09a3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/analysis/emails_augmented.csv')  # Update path if necessary\n",
    "assert 'body' in df.columns and 'label' in df.columns, \"Missing required columns.\"\n",
    "df = preprocess(df)\n",
    "X = df['clean_email']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e035ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorizing\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(df['clean_email'])\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d148b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e172ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Different Models\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478b1f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression with Grid Search and K-fold cross-validation\n",
    "model = LogisticRegression()\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['liblinear'],  # Efficient for sparse text features\n",
    "        'max_iter': [500]\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['l2'],\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['saga'],  # Faster on large data\n",
    "        'max_iter': [1000]\n",
    "    }\n",
    "]\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=kfold,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X, y) \n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "results.append({\n",
    "    'Model': 'LogisticRegression()',\n",
    "    'Best Params': grid_search.best_params_,\n",
    "    'CV Accuracy': grid_search.best_score_,\n",
    "    'Test Accuracy': accuracy_score(y_test, y_pred),\n",
    "    'Test Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "    'Test Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "    'Test F1': f1_score(y_test, y_pred, average='weighted')\n",
    "})\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0787723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3b6402",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y, test_size=0.2, random_state=42)\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43424bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian Naive Bayes with Grid Search and K-fold cross-validation\n",
    "model = MultinomialNB()\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1.0],  \n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=kfold,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "results.append({\n",
    "    'Model': 'MultinomialNB',\n",
    "    'Best Params': grid_search.best_params_,\n",
    "    'CV Accuracy': grid_search.best_score_,\n",
    "    'Test Accuracy': accuracy_score(y_test, y_pred),\n",
    "    'Test Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "    'Test Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "    'Test F1': f1_score(y_test, y_pred, average='weighted')\n",
    "})\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb91126",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0f76ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn import svm\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y, test_size=0.2, random_state=42)\n",
    "clf = svm.SVC()\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b891034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Classification with Grid Search and K-fold cross-validation\n",
    "model = svm.SVC()\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'kernel': ['linear'],\n",
    "        'C': [0.1, 1, 10],\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': [0.1, 1, 10],\n",
    "        'gamma': [1e-3, 1e-4]\n",
    "    }\n",
    "]\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=kfold,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X, y) \n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "results.append({\n",
    "    'Model': 'SVC',\n",
    "    'Best Params': grid_search.best_params_,\n",
    "    'CV Accuracy': grid_search.best_score_,\n",
    "    'Test Accuracy': accuracy_score(y_test, y_pred),\n",
    "    'Test Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "    'Test Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "    'Test F1': f1_score(y_test, y_pred, average='weighted')\n",
    "})\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791315bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0b4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#default random forest \n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y, test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d35605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest with Grid Search and K-fold cross-validation\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],              \n",
    "    'max_depth': [10, 20, None],             \n",
    "    'max_features': ['sqrt', 'log2'],        \n",
    "    'min_samples_leaf': [1, 2]               \n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=kfold,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X, y) \n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Random Forest Classifier',\n",
    "    'Best Params': grid_search.best_params_,\n",
    "    'CV Accuracy': grid_search.best_score_,\n",
    "    'Test Accuracy': accuracy_score(y_test, y_pred),\n",
    "    'Test Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "    'Test Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "    'Test F1': f1_score(y_test, y_pred, average='weighted')\n",
    "})\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb19cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "coefs = model.coef_[0]\n",
    "top_phishing_idx = np.argsort(coefs)[-10:]\n",
    "top_legit_idx = np.argsort(coefs)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5076a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fae64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Melt the DataFrame for seaborn\n",
    "metrics_df = results.melt(id_vars='Model', \n",
    "                             value_vars=['Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1'], \n",
    "                             var_name='Metric', \n",
    "                             value_name='Score')\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=metrics_df, x='Model', y='Score', hue='Metric')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=15)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f89b6236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/rise-phishing/connorhl/.conda/envs/phishing_env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                            subject  \\\n",
      "0           0                          Never agree to be a loser   \n",
      "1           1                             Befriend Jenna Jameson   \n",
      "2           2                               CNN.com Daily Top 10   \n",
      "3           3  Re: svn commit: r619753 - in /spamassassin/tru...   \n",
      "4           4                         SpecialPricesPharmMoreinfo   \n",
      "\n",
      "                                                body  label  num_urls  \\\n",
      "0  Buck up, your troubles caused by small dimensi...      1         1   \n",
      "1  \\nUpgrade your sex and pleasures with these te...      1         1   \n",
      "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...      1        29   \n",
      "3  Would anyone object to removing .so from this ...      0       939   \n",
      "4  \\nWelcomeFastShippingCustomerSupport\\nhttp://7...      1         1   \n",
      "\n",
      "   num_words  num_chars_foreign  num_chars_special  num_urgent_words  \\\n",
      "0         46                  0                 13                 0   \n",
      "1          9                  0                  5                 0   \n",
      "2        302                  0                722                 1   \n",
      "3       2660                  0               5769                 1   \n",
      "4          2                  0                 13                 0   \n",
      "\n",
      "   num_stopwords                                  body_no_stopwords  \n",
      "0             24  buck troubles caused small dimension soon beco...  \n",
      "1              4              upgrade sex pleasures techniques http  \n",
      "2             64  daily top top videos stories aug pm edt top vi...  \n",
      "3            142  would anyone object removing list tld basicall...  \n",
      "4              0            welcomefastshippingcustomersupport http  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8206/8206 [14:47<00:00,  9.25it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1031\n",
      "Validation Accuracy: 98.03%\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8206/8206 [14:44<00:00,  9.27it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0281\n",
      "Validation Accuracy: 99.18%\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8206/8206 [14:44<00:00,  9.28it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0080\n",
      "Validation Accuracy: 99.31%\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8206/8206 [14:43<00:00,  9.28it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0030\n",
      "Validation Accuracy: 99.31%\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8206/8206 [14:44<00:00,  9.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0028\n",
      "Validation Accuracy: 99.31%\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8206/8206 [14:44<00:00,  9.28it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0031\n",
      "Validation Accuracy: 99.31%\n",
      "Model saved to ./phishing-bert-model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    " \n",
    "\n",
    "df = pd.read_csv('../data/analysis/emails_augmented.csv')\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "\n",
    "class EmailDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.df.iloc[idx]['body_no_stopwords'])\n",
    "        label = int(self.df.iloc[idx]['label'])\n",
    "        encodings = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encodings['input_ids'].squeeze()\n",
    "        attention_mask = encodings['attention_mask'].squeeze()\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': torch.tensor(label)\n",
    "        }\n",
    "\n",
    "\n",
    "train_ds = EmailDataset(train_df, tokenizer)\n",
    "val_ds = EmailDataset(val_df, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=8)\n",
    "\n",
    "\n",
    "num_labels = df['label'].nunique()\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-large-uncased',\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "total_steps = len(train_loader) * 3  # 3 epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "\n",
    "for epoch in range(6):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"Validation Accuracy: {acc:.2%}\")\n",
    "\n",
    "model.save_pretrained('./phishing-bert-model')\n",
    "tokenizer.save_pretrained('./phishing-bert-model')\n",
    "print(\"Model saved to ./phishing-bert-model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7186d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix with counts and percentages to BERT_confusion_matrix.png\n",
      "Saved learning curve to BERT_learning_curve.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# --- Paths ---\n",
    "MODEL_PATH = \"./phishing-bert-model\"\n",
    "DATA_PATH = \"../data/analysis/emails_augmented.csv\"\n",
    "OUTPUT_CM = \"BERT_confusion_matrix.png\"\n",
    "\n",
    "# --- Load Model and Tokenizer ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_PATH).to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n",
    "model.eval()\n",
    "\n",
    "# --- Dataset Class ---\n",
    "class EmailDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.df.iloc[idx][\"body_no_stopwords\"])  # or \"body\" if you want full text\n",
    "        label = int(self.df.iloc[idx][\"label\"])\n",
    "        encodings = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encodings[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encodings[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(label)\n",
    "        }\n",
    "\n",
    "# --- Load Data ---\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "val_df = df.sample(frac=0.2, random_state=42)  # mimic validation set\n",
    "val_ds = EmailDataset(val_df, tokenizer)\n",
    "val_loader = DataLoader(val_ds, batch_size=16)\n",
    "\n",
    "# --- Collect Predictions ---\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_sum = np.sum(cm)\n",
    "cm_perc = cm / cm_sum * 100\n",
    "\n",
    "labels = np.array([[\"TN\", \"FP\"], [\"FN\", \"TP\"]])\n",
    "annot = np.empty_like(cm).astype(str)\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        c = cm[i, j]\n",
    "        p = cm_perc[i, j]\n",
    "        label = labels[i, j]\n",
    "        annot[i, j] = f\"{label}\\n{c}\\n{p:.1f}%\"\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=annot,\n",
    "    fmt=\"\",\n",
    "    cmap=\"Blues\",\n",
    "    cbar=False,\n",
    "    xticklabels=[0, 1],\n",
    "    yticklabels=[0, 1],\n",
    "    linewidths=1,\n",
    "    linecolor=\"black\",\n",
    "    square=True\n",
    ")\n",
    "plt.title(\"BERT - Confusion Matrix\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.savefig(OUTPUT_CM, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(f\"Saved confusion matrix with counts and percentages to {OUTPUT_CM}\")\n",
    "\n",
    "\n",
    "# --- Learning Curve ---\n",
    "train_sizes = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "train_scores, val_scores = [], []\n",
    "\n",
    "for frac in train_sizes:\n",
    "    frac_train_df = train_df.sample(frac=frac, random_state=42) if frac < 1.0 else train_df.copy()\n",
    "    frac_train_ds = EmailDataset(frac_train_df, tokenizer)\n",
    "    frac_train_loader = DataLoader(frac_train_ds, batch_size=16)\n",
    "\n",
    "    # Training Accuracy\n",
    "    y_true_train, y_pred_train = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in frac_train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            y_true_train.extend(labels.cpu().numpy())\n",
    "            y_pred_train.extend(preds.cpu().numpy())\n",
    "\n",
    "    train_acc = accuracy_score(y_true_train, y_pred_train)\n",
    "\n",
    "    # Validation Accuracy\n",
    "    y_true_val, y_pred_val = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            y_true_val.extend(labels.cpu().numpy())\n",
    "            y_pred_val.extend(preds.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(y_true_val, y_pred_val)\n",
    "\n",
    "    train_scores.append(train_acc)\n",
    "    val_scores.append(val_acc)\n",
    "\n",
    "# Plot Learning Curve\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(np.array(train_sizes) * len(train_df), train_scores, 'o-', color=\"blue\", label=\"Training Accuracy\")\n",
    "plt.plot(np.array(train_sizes) * len(train_df), val_scores, 's--', color=\"green\", label=\"Validation Accuracy\")\n",
    "plt.title(\"Learning Curve - BERT\")\n",
    "plt.xlabel(\"Training Set Size\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(OUTPUT_LC, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"Saved learning curve to {OUTPUT_LC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f077f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/rise-phishing/connorhl/.conda/envs/phishing_env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('./phishing-bert-model')\n",
    "tokenizer = BertTokenizer.from_pretrained('./phishing-bert-model')\n",
    "model.eval()\n",
    "\n",
    "def classify_email(email_text):\n",
    "    inputs = tokenizer(email_text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        probs = F.softmax(logits, dim=1).squeeze().numpy()\n",
    "    label = int(probs.argmax())\n",
    "    return label, probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66b34c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API')\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def gpt_explanation(email_text):\n",
    "    prompt = f\"\"\"The following email was classified as a phishing attempt. Explain in one sentence why:\n",
    "\"{email_text}\"\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a cybersecurity analyst trained to explain phishing emails.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=100,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dff79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Explanation:\", gpt_explanation(email_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964d4703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, BertTokenizer, BertForSequenceClassification\n",
    "import shap\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('./phishing-bert-model')\n",
    "tokenizer = BertTokenizer.from_pretrained('./phishing-bert-model')\n",
    "\n",
    "# Create a transformers pipeline (SHAP expects this)\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, return_all_scores=True)\n",
    "\n",
    "# Email example\n",
    "email_text = \"\"\"\n",
    "Can anyone help with the following:\n",
    "\n",
    "I get:\n",
    "\n",
    " > mcmcsamp(txt.lmer3f)\n",
    "Markov Chain Monte Carlo (MCMC) output:\n",
    "Start = 1\n",
    "End = 1\n",
    "Thinning interval = 1\n",
    "....\n",
    "\n",
    "But:\n",
    "\n",
    " > mcsamp(txt.lmer3f)\n",
    "Error in as.bugs.array(sims, program = \"\"lmer\"\", n.iter = n.iter,  \n",
    "n.burnin = n.burnin,  :\n",
    "\terror in parameter sigma.s in parameters.to.save\n",
    "\n",
    "\n",
    "I had attached the arm package:\n",
    " > library(arm)\n",
    "Loading required package: R2WinBUGS\n",
    "\n",
    "arm (Version 1.0-15, built: 2007-3-17)\n",
    "Working directory is /Users/mk/Documents/projects/Mike/prediss/Exp-Text\n",
    "Loading required package: foreign\n",
    "\n",
    " > sessionInfo()\n",
    "R version 2.4.1 (2006-12-18)\n",
    "i386-apple-darwin8.8.1\n",
    "\n",
    "locale:\n",
    "C\n",
    "\n",
    "attached base packages:\n",
    "[1] \"\"tools\"\"     \"\"grid\"\"      \"\"datasets\"\"  \"\"stats\"\"     \"\"graphics\"\"   \n",
    "\"\"grDevices\"\" \"\"utils\"\"     \"\"methods\"\"\n",
    "[9] \"\"base\"\"\n",
    "\n",
    "other attached packages:\n",
    "      foreign          arm    R2WinBUGS         coda         \n",
    "Hmisc      gmodels      effects         lme4\n",
    "     \"\"0.8-18\"\"     \"\"1.0-15\"\"      \"\"2.0-4\"\"     \"\"0.10-7\"\"      \"\"3.2-1\"\"      \n",
    "\"\"2.13.2\"\"      \"\"1.0-9\"\"  \"\"0.9975-13\"\"\n",
    "       Matrix          car       weaver    codetools        \n",
    "digest       xtable latticeExtra      lattice\n",
    "\"\"0.9975-11\"\"      \"\"1.2-1\"\"      \"\"1.0.1\"\"      \"\"0.0-3\"\"      \"\"0.2.3\"\"       \n",
    "\"\"1.4-3\"\"      \"\"0.1-4\"\"    \"\"0.14-17\"\"\n",
    "     gridBase         MASS          JGR       iplots        \n",
    "JavaGD        rJava\n",
    "      \"\"0.4-3\"\"     \"\"7.2-33\"\"     \"\"1.4-15\"\"      \"\"1.0-5\"\"      \"\"0.3-6\"\"      \n",
    "\"\"0.4-14\"\"\n",
    "\n",
    "Thanks,\n",
    "MK\n",
    "\"\"\"\n",
    "\n",
    "# SHAP Explainer\n",
    "explainer = shap.Explainer(pipe, shap.maskers.Text(tokenizer))\n",
    "shap_values = explainer([email_text])  # must be list[str]\n",
    "\n",
    "# Plot\n",
    "shap.plots.text(shap_values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc1d2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTop indicative words for phishing:\")\n",
    "for word, coef in zip(feature_names[top_phishing_idx], coefs[top_phishing_idx]):\n",
    "    print(f\"{word}: {coef:.4f}\")\n",
    "\n",
    "print(\"\\nTop indicative words for legitimate:\")\n",
    "for word, coef in zip(feature_names[top_legit_idx], coefs[top_legit_idx]):\n",
    "    print(f\"{word}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(vectorizer, model)\n",
    "explainer = lime.lime_text.LimeTextExplainer(class_names=['Legitimate', 'Phishing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f4b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "idx = random.randint(0, len(df) - 1)\n",
    "print(\"\\nExplaining instance:\", df['clean_email'].iloc[idx])\n",
    "exp = explainer.explain_instance(df['clean_email'].iloc[idx], pipeline.predict_proba, num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef1120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_dir = './generated'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "exp.save_to_file(os.path.join(output_dir, 'lime_explanation.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec5acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model, './generated/phishing_model.pkl')\n",
    "joblib.dump(vectorizer, './generated/tfidf_vectorizer.pkl')\n",
    "\n",
    "print(\"\\nModel and vectorizer saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
