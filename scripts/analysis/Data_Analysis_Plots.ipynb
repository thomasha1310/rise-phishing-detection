{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00994b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, learning_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef979cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_email(text: str) -> str:\n",
    "    text = re.sub(r'<[^>]+>', '', text) # remove HTML tags\n",
    "    text = re.sub(r'http\\S+', '', text) # remove URLs\n",
    "    # TODO: add a count of URLs to email data\n",
    "    text = re.sub(r'\\d+', '', text) # remove numerical text\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove punctuation\n",
    "    text = text.lower().strip() # lowercase\n",
    "    return text\n",
    "\n",
    "def preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    df['clean_email'] = df['body'].astype(str).apply(clean_email)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4852fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/analysis/emails_augmented.csv') \n",
    "assert 'body' in df.columns and 'label' in df.columns, \"Missing required columns.\"\n",
    "df = preprocess(df)\n",
    "X = df['clean_email']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5e7f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression = joblib.load('../../output/models/LogisticRegression.joblib')\n",
    "MLPClassifier = joblib.load('../../output/models/LogisticRegression.joblib')\n",
    "MultinomialNB = joblib.load('../../output/models/LogisticRegression.joblib')\n",
    "RandomForest = joblib.load('../../output/models/LogisticRegression.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60248d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Learning Curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate learning curve data\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "    estimator= LogisticRegression,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=kfold,\n",
    "    scoring='accuracy',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Compute mean and std\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "validation_scores_std = np.std(validation_scores, axis=1)\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='blue', label='Training Score')\n",
    "plt.plot(train_sizes, validation_scores_mean, 'o-', color='green', label='Validation Score')\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color='blue')\n",
    "plt.fill_between(train_sizes, validation_scores_mean - validation_scores_std,\n",
    "                 validation_scores_mean + validation_scores_std, alpha=0.1, color='green')\n",
    "plt.title('Learning Curve - Logistic Regression Pipeline')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('../../output/results/LogisticRegression_learning_curve.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP Classifier Learning Curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate learning curve data\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "    estimator= MLPClassifier,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=kfold,\n",
    "    scoring='accuracy',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Compute mean and std\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "validation_scores_std = np.std(validation_scores, axis=1)\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='blue', label='Training Score')\n",
    "plt.plot(train_sizes, validation_scores_mean, 'o-', color='green', label='Validation Score')\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color='blue')\n",
    "plt.fill_between(train_sizes, validation_scores_mean - validation_scores_std,\n",
    "                 validation_scores_mean + validation_scores_std, alpha=0.1, color='green')\n",
    "plt.title('Learning Curve - Logistic Regression Pipeline')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('../../output/results/MLPClassifier_learning_curve.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81872b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MultinomialNB Learning Curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate learning curve data\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "    estimator= MultinomialNB,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=kfold,\n",
    "    scoring='accuracy',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Compute mean and std\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "validation_scores_std = np.std(validation_scores, axis=1)\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='blue', label='Training Score')\n",
    "plt.plot(train_sizes, validation_scores_mean, 'o-', color='green', label='Validation Score')\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color='blue')\n",
    "plt.fill_between(train_sizes, validation_scores_mean - validation_scores_std,\n",
    "                 validation_scores_mean + validation_scores_std, alpha=0.1, color='green')\n",
    "plt.title('Learning Curve - Logistic Regression Pipeline')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('../../output/results/MultinomialNB_learning_curve.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa80fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest Learning Curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate learning curve data\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "    estimator= RandomForest,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=kfold,\n",
    "    scoring='accuracy',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Compute mean and std\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "validation_scores_std = np.std(validation_scores, axis=1)\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='blue', label='Training Score')\n",
    "plt.plot(train_sizes, validation_scores_mean, 'o-', color='green', label='Validation Score')\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color='blue')\n",
    "plt.fill_between(train_sizes, validation_scores_mean - validation_scores_std,\n",
    "                 validation_scores_mean + validation_scores_std, alpha=0.1, color='green')\n",
    "plt.title('Learning Curve - Logistic Regression Pipeline')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('../../output/results/RandomForest_learning_curve.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f71d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combined Learning Curve\n",
    "from sklearn.model_selection import learning_curve, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function to plot learning curve for one model\n",
    "def plot_learning_curve(ax, model, label, color, X, y, cv):\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        estimator=model,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        cv=cv,\n",
    "        scoring='accuracy',\n",
    "        train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "    ax.plot(train_sizes, train_mean, 'o-', color=color, label=f'{label} - Train')\n",
    "    ax.plot(train_sizes, val_mean, '--', color=color, label=f'{label} - Validation')\n",
    "    ax.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=color)\n",
    "    ax.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color=color)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression,\n",
    "    'MLP': MLPClassifier,\n",
    "    'Random Forest': RandomForest,\n",
    "    'Naive Bayes': MultinomialNB\n",
    "}\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'orange']\n",
    "\n",
    "# Set up plot\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Plot all models\n",
    "for (label, model), color in zip(models.items(), colors):\n",
    "    plot_learning_curve(ax, model, label, color, X_train, y_train, cv)\n",
    "\n",
    "# Final formatting\n",
    "ax.set_title('Learning Curves - Model Comparison')\n",
    "ax.set_xlabel('Training Set Size')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True)\n",
    "fig.tight_layout()\n",
    "fig.savefig('../../output/results/combined_learning_curves.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458eceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Confusion Matrix\n",
    "y_pred = LogisticRegression.predict(X_test)\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [f\"{value:0.0f}\" for value in cf_matrix.flatten()]\n",
    "group_percentages = [f\"{value:.2%}\" for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
    "\n",
    "labels = [f\"{name}\\n{count}\\n{percent}\" for name, count, percent in zip(group_names, group_counts, group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2, 2)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues', cbar=False, linewidths=0.5, linecolor='gray')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../output/results/LogisticRegression_confusion_matrix.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a16dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP Classifier Confusion Matrix\n",
    "y_pred = MLPClassifier.predict(X_test)\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [f\"{value:0.0f}\" for value in cf_matrix.flatten()]\n",
    "group_percentages = [f\"{value:.2%}\" for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
    "\n",
    "labels = [f\"{name}\\n{count}\\n{percent}\" for name, count, percent in zip(group_names, group_counts, group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2, 2)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues', cbar=False, linewidths=0.5, linecolor='gray')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../output/results/MLPClassifier_confusion_matrix.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MultinomialNB Confusion Matrix\n",
    "y_pred = MultinomialNB.predict(X_test)\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [f\"{value:0.0f}\" for value in cf_matrix.flatten()]\n",
    "group_percentages = [f\"{value:.2%}\" for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
    "\n",
    "labels = [f\"{name}\\n{count}\\n{percent}\" for name, count, percent in zip(group_names, group_counts, group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2, 2)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues', cbar=False, linewidths=0.5, linecolor='gray')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../output/results/MultinomialNB_confusion_matrix.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fe9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest Confusion Matrix\n",
    "y_pred = RandomForest.predict(X_test)\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [f\"{value:0.0f}\" for value in cf_matrix.flatten()]\n",
    "group_percentages = [f\"{value:.2%}\" for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
    "\n",
    "labels = [f\"{name}\\n{count}\\n{percent}\" for name, count, percent in zip(group_names, group_counts, group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2, 2)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues', cbar=False, linewidths=0.5, linecolor='gray')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../output/results/RandomForest_confusion_matrix.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
